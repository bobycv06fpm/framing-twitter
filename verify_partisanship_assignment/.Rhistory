replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples = 1000
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples = 100
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples = 100
n_samples %>%
replicate(fun.is_significant(1000)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(10000)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100000)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
fun.get_nums = function(sample_size){
sum = n_samples %>%
replicate(fun.is_significant(sample_size)) %>%
sum()
return(sum)
}
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
repl = 100
fun.get_nums = function(sample_size){
sum = n_samples %>%
replicate(fun.is_significant(sample_size)) %>%
sum()
return(sum)
}
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
p <- ggplot(df.data, aes(x=var)) +
geom_density()
ggplot(df.data, aes(x=var)) +
geom_density()
df.data = tibble(
var = replicate(repl, fun.get_nums(100))
)
df.data = tibble(
var = replicate(repl, fun.get_nums(100))
)
ggplot(df.data, aes(x=var)) +
geom_density()
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
ggplot(df.data, aes(x=var)) +
geom_density()
df.data = tibble(
var = replicate(repl, fun.get_nums(100))
)
df.data = tibble(
var = replicate(repl, fun.get_nums(100))
)
ggplot(df.data, aes(x=var)) +
geom_density()
n_samples %>%
replicate(fun.is_significant(20)) %>%
sum()
n_samples %>%
replicate(fun.is_significant(100)) %>%
sum()
sum = n_samples %>%
replicate(fun.is_significant(sample_size)) %>%
sum()
return(sum)
fun.get_nums = function(sample_size){
sum = n_samples %>%
replicate(fun.is_significant(sample_size)) %>%
sum()
return(sum)
}
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
ggplot(df.data, aes(x=var)) +
geom_density()
df.data = tibble(
var = replicate(repl, fun.get_nums(100))
)
df.data = tibble(
var = replicate(repl, fun.get_nums(100))
)
ggplot(df.data, aes(x=var)) +
geom_density()
ggplot(df.data, aes(x=var)) +
geom_histogram()
ggplot(df.data, aes(x=var)) +
geom_histogram(bins=100)
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
df.data = tibble(
var = replicate(repl, fun.get_nums(20))
)
ggplot(df.data, aes(x=var)) +
geom_density()
df.data2 = tibble(
var = replicate(repl, fun.get_nums(100))
)
ggplot(df.data2, aes(x=var)) +
geom_histogram(bins=100)
ggplot(df.data2, aes(x=var)) +
geom_density()
# turn predictors into factors
df.placement = df.placement %>%
mutate(school = as.factor(school))
# define contrasts
contrasts(df.placement$school) = cbind(east_vs_west=c(-1, 2 ,-1),
berk_vs_stan=c(-1, 0, 1))
# define contrasts
contrasts(df.placement$school) = cbind(east_vs_west=c(-1, 2 ,-1),
berk_vs_stan=c(-1, 0, 1))
# fit the model
fit = lm(formula = salary ~ 1 + school,
data = df.placement)
# print the model summary
fit %>%
summary()
# write your code here
df.a = lm.a %>%
augment() %>%
clean_names()
ggplot(data = df.placement,
mapping = aes(x = school,
y = salary,
group = type,
color = type)) +
geom_smooth(method = "lm", se = F) +
stat_summary(fun.y = "mean",
geom = "point",
aes(color = type),
size = 3) +
scale_color_brewer(palette = "Set1") +
theme(legend.position = c(0.2, 0.9)) +
guides(color = guide_legend(reverse = T))
ggplot(data = df.placement,
mapping = aes(x = school,
y = salary,
group = type,
color = type)) +
geom_smooth(method = "lm", se = F) +
stat_summary(fun.y = "mean",
geom = "point",
aes(color = type),
size = 3,
alpha = 0.3) +
scale_color_brewer(palette = "Set1") +
theme(legend.position = c(0.2, 0.9)) +
guides(color = guide_legend(reverse = T))
# write your code here
df.placement = df.placement %>%
mutate(type = as.factor(type))
tibble(
variable = c("`year`", "`school`", "`type`", "`salary`"),
description = c("Year of graduation",
"University",
"Career typr",
"Annual salary in dollars")
) %>%
kable(align = "l",
caption = "Variables in the (hypothetical!) placement data set.")
View(df.placement)
# write your code here
df.placement = df.placement %>%
mutate(year = as.factor(year))
# write your code here
df.placement = df.placement %>%
mutate(year = as.factor(year))
# define contrasts
contrasts(df.placement$year) = cbind(rest_vs_2016=c(2, -1 ,-1),
c_2017_2018=c(0, 1, -1))
# fit the model
fit = lm(formula = salary ~ 1 + year,
data = df.placement)
# print the model summary
fit %>%
summary()
# Based on the question, I'm not sure if we're supposed plot the lines separately for novices and experts or plot them together. Just in case, I'll do both.
ggplot(df.motivation,
aes(x = difficulty,
y = score)) +
geom_smooth(method = "lm") +
geom_point(alpha = 0.3) +
scale_color_brewer(palette = "Set1")
# Here's a plot that shows the relationship separately for the two groups
ggplot(df.motivation,
aes(x = difficulty,
y = score,
group = train,
color = train)) +
geom_smooth(method = "lm", se=F) +
geom_point(alpha = 0.3) +
scale_color_brewer(palette = "Set1")
# write your code here
lm(score ~ 1 + difficulty + train + difficulty * train, data = df.motivation) %>%
anova()
tibble(
variable = c("`score`", "`difficulty`", "`train`"),
description = c("Test score (higher is better)",
"Level of difficulty (from low to high)",
"Expert or novice")
) %>%
kable(align = "l",
caption = "Variables in the motivation data set.")
# write your code here
lm(score ~ 1 + difficulty + train + difficulty * train, data = df.motivation) %>%
summary()
# write your code here
lm(score ~ 1 + difficulty + train, data = df.motivation) %>%
summary()
lm(score ~ 1 + difficulty + train, data = df.motivation) %>%
tidy(conf.int = TRUE)
# write your code here
lm.mot = lm(score ~ 1 + difficulty + train, data = df.motivation)
df.motivation %>%
group_by(train) %>%
summarize(mean = mean(score),
sd = sd(score))
lm(score ~ 1 + difficulty + train + difficulty * train, data = df.motivation) %>%
anova()
# write your code here
lm.mot = lm(score ~ 1 + difficulty * train, data = df.motivation)
lm.mot %>%
summary()
# write your code here
lm.mot = lm(score ~ 1 + difficulty + train + difficulty * train, data = df.motivation)
lm.mot %>%
summary()
lm(score ~ 1 + difficulty + train + difficulty * train, data = df.motivation) %>%
anova()
# write your code here
lm.mot = lm(score ~ 1 + difficulty + train + difficulty * train, data = df.motivation)
lm.mot %>%
summary()
# write your code here
lm.mot = lm(score ~ 1 + difficulty + train, data = df.motivation)
lm.mot %>%
summary()
lm.mot %>%
tidy(conf.int = TRUE)
df.motivation %>%
group_by(train) %>%
summarize(mean = mean(score),
sd = sd(score))
lm(score ~ 1 + difficulty + train + difficulty * train, data = df.motivation) %>%
anova()
library("emmeans")
install.packages("emmeans")
library("emmeans")
# write your code here
df.placement = df.placement %>%
mutate(difficulty = as.factor(difficulty))
# write your code here
df.motivation = df.motivation %>%
mutate(difficulty = as.factor(difficulty))
fit = lm(formula = score ~ difficulty,
data = df.motivation)
# post hoc tests
leastsquare = emmeans(fit, "difficulty")
pairs(leastsquare,
adjust = "bonferroni")
library(ggplot2)
library(ggrepel)
library(RColorBrewer)
setwd('/Users/ddemszky/Google_Drive/Research/Framing/NAACL/framing-twitter')
# plot overall polarization
data <- read.csv("data/polarization_clustered_relative.csv",header=TRUE)
# plot overall polarization
data <- read.csv("data/polarization_noRT.csv",header=TRUE)
ggplot(data, aes(x=year, y=polarization, color=is_actual))+
stat_smooth(aes(group=is_actual), method=lm, se=TRUE, fullrange=TRUE) +
geom_line(aes(group=label), color='gray75', linetype='dashed') +
geom_point(aes(fill=is_actual), pch=21, size=2, colour='gray20')+
geom_point() +
geom_point(shape=1, size=2, colour='gray20') +
geom_text_repel(data=subset(data, is_actual == 'actual value'), aes(label=label),color='gray10', show.legend = FALSE) +
xlab('Year') +
ylab('Leave-out Estimate of Phrase Partisanship') +
theme_bw() +
theme(legend.position="top", legend.direction="horizontal", legend.title = element_blank(), legend.box.margin=margin(-1,-10,-10,-10), panel.grid.major.x = element_blank(), panel.grid.minor = element_blank()) +
scale_color_manual(values=c("indianred2", "lightsteelblue3")) +
scale_x_continuous(limits = c(2015.5,2019.05), expand = c(0, 0))
data <- read.csv("data/topic_polarization_relative.csv",header=TRUE)
ggplot(data, aes(x=year, y=polarization, color=kind))+
stat_smooth(aes(group=kind), method=lm, se=TRUE, fullrange=TRUE) +
geom_line(aes(group=label), color='gray75', linetype='dashed') +
geom_point(aes(fill=kind), pch=21, size=2, colour='gray20')+
geom_point() +
geom_point(shape=1, size=2, colour='gray20') +
geom_text_repel(data=subset(data, kind == 'within-topic'), aes(label=label),color='gray10', show.legend = FALSE) +
xlab('Year') +
ylab('Polarization') +
theme_bw() +
theme(legend.position="top", legend.direction="horizontal", legend.title = element_blank(), legend.box.margin=margin(0,0,-10,0), legend.text = element_text(margin = margin(r =100, unit = "pt")), panel.grid.major.x = element_blank(), panel.grid.minor = element_blank()) +
scale_color_manual(values=c("darkolivegreen4", "deeppink4")) +
scale_x_continuous(limits = c(2015.5,2019.05), expand = c(0, 0))
data <- read.csv("data/topic_polarization.csv",header=TRUE)
ggplot(data, aes(x=year, y=polarization, color=kind))+
stat_smooth(aes(group=kind), method=lm, se=TRUE, fullrange=TRUE) +
geom_line(aes(group=label), color='gray75', linetype='dashed') +
geom_point(aes(fill=kind), pch=21, size=2, colour='gray20')+
geom_point() +
geom_point(shape=1, size=2, colour='gray20') +
geom_text_repel(data=subset(data, kind == 'within-topic'), aes(label=label),color='gray10', show.legend = FALSE) +
xlab('Year') +
ylab('Polarization') +
theme_bw() +
theme(legend.position="top", legend.direction="horizontal", legend.title = element_blank(), legend.box.margin=margin(0,0,-10,0), legend.text = element_text(margin = margin(r =100, unit = "pt")), panel.grid.major.x = element_blank(), panel.grid.minor = element_blank()) +
scale_color_manual(values=c("darkolivegreen4", "deeppink4")) +
scale_x_continuous(limits = c(2015.5,2019.05), expand = c(0, 0))
data <- read.csv("data/topic_polarization_relative.csv",header=TRUE)
ggplot(data, aes(x=year, y=polarization, color=kind))+
stat_smooth(aes(group=kind), method=lm, se=TRUE, fullrange=TRUE) +
geom_line(aes(group=label), color='gray75', linetype='dashed') +
geom_point(aes(fill=kind), pch=21, size=2, colour='gray20')+
geom_point() +
geom_point(shape=1, size=2, colour='gray20') +
geom_text_repel(data=subset(data, kind == 'within-topic'), aes(label=label),color='gray10', show.legend = FALSE) +
xlab('Year') +
ylab('Polarization') +
theme_bw() +
theme(legend.position="top", legend.direction="horizontal", legend.title = element_blank(), legend.box.margin=margin(0,0,-10,0), legend.text = element_text(margin = margin(r =100, unit = "pt")), panel.grid.major.x = element_blank(), panel.grid.minor = element_blank()) +
scale_color_manual(values=c("darkolivegreen4", "deeppink4")) +
scale_x_continuous(limits = c(2015.5,2019.05), expand = c(0, 0))
library(ggplot2)
library(ggrepel)
setwd('./verify_partisanship_assignment')
data <- read.csv("verify_party_assignment.csv", header=TRUE)
# We exclude DC because it has a disproportionately large number of news media Twitter handles that make it an outlier. Moreover, DC is not an official state.
data = data[data$abbr != 'DC',]
library(ggplot2)
library(ggrepel)
setwd('./verify_partisanship_assignment')
library(ggrepel)
data <- read.csv("verify_party_assignment.csv", header=TRUE)
data$avg_part <- rowMeans(subset(data, select = c(rep_share, rep_twitter)), na.rm = TRUE)
ggplot(data) +
geom_smooth(method='lm', aes(x=rep_share, y=rep_twitter, weight=partisan_twitter), size=.1, color='black', se=TRUE, fullrange=TRUE)  +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter, color=avg_part)) +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter), shape = 1,colour = "black") +
geom_text_repel(aes(x=rep_share, y=rep_twitter, label=abbr), size=3.7) +
scale_color_distiller("Avg partisanship", palette = "RdBu", limits=c(0,1)) +
theme_bw() +
labs(x='Rep share in 2016 elections', y='Proportion of Rep users in our data', title='', size='No. of partisan\nusers') +
scale_y_continuous(breaks=seq(0,1,.1)) + scale_x_continuous(breaks=seq(0,1,.1), expand=c(0,0), limits=c(0.3, .77))  +
theme(legend.background = element_rect(color="black",size = 0.1),legend.margin=margin(c(4,4,5,4)), legend.title=element_text(size=8))
library(ggplot2)
library(ggrepel)
data <- read.csv("verify_party_assignment.csv", header=TRUE)
data$avg_part <- rowMeans(subset(data, select = c(rep_share, rep_twitter)), na.rm = TRUE)
ggplot(data) +
geom_smooth(method='lm', aes(x=rep_share, y=rep_twitter, weight=partisan_twitter), size=.1, color='black', se=TRUE, fullrange=TRUE)  +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter, color=avg_part)) +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter), shape = 1,colour = "black") +
geom_text_repel(aes(x=rep_share, y=rep_twitter, label=abbr), size=3.7) +
scale_color_distiller("Avg partisanship", palette = "RdBu", limits=c(0,1)) +
theme_bw() +
labs(x='Rep share in 2016 elections', y='Proportion of Rep users in our data', title='', size='No. of partisan\nusers') +
scale_y_continuous(breaks=seq(0,1,.1)) + scale_x_continuous(breaks=seq(0,1,.1), expand=c(0,0), limits=c(0.3, .77))  +
theme(legend.background = element_rect(color="black",size = 0.1),legend.margin=margin(c(4,4,5,4)), legend.title=element_text(size=8))
ggplot(data) +
geom_smooth(method='lm', aes(x=rep_share, y=rep_twitter, weight=partisan_twitter), size=.1, color='black', se=TRUE, fullrange=TRUE)  +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter, color=avg_part)) +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter), shape = 1,colour = "black") +
geom_text_repel(aes(x=rep_share, y=rep_twitter, label=abbr), size=3.7) +
scale_color_distiller("Avg partisanship", palette = "RdBu", limits=c(0,1)) +
theme_bw() +
labs(x='Rep share in 2016 elections', y='Proportion of Rep users in our data', title='', size='No. of partisan\nusers') +
scale_y_continuous(breaks=seq(0,1,.1)) + scale_x_continuous(breaks=seq(0,1,.1), expand=c(0,0), limits=c(0.1, .77))  +
theme(legend.background = element_rect(color="black",size = 0.1),legend.margin=margin(c(4,4,5,4)), legend.title=element_text(size=8))
ggplot(data) +
geom_smooth(method='lm', aes(x=rep_share, y=rep_twitter, weight=partisan_twitter), size=.1, color='black', se=TRUE, fullrange=TRUE)  +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter, color=avg_part)) +
geom_point(aes(x=rep_share, y=rep_twitter, size=partisan_twitter), shape = 1,colour = "black") +
geom_text_repel(aes(x=rep_share, y=rep_twitter, label=abbr), size=3.7) +
scale_color_distiller("Avg partisanship", palette = "RdBu", limits=c(0,1)) +
theme_bw() +
labs(x='Rep share in 2016 elections', y='Proportion of Rep users in our data', title='', size='No. of partisan\nusers') +
scale_y_continuous(breaks=seq(0,1,.1)) + scale_x_continuous(breaks=seq(0,1,.1), expand=c(0,0), limits=c(0.01, .77))  +
theme(legend.background = element_rect(color="black",size = 0.1),legend.margin=margin(c(4,4,5,4)), legend.title=element_text(size=8))
