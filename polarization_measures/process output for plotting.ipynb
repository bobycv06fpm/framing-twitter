{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from helpers.funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('../config.json', 'r'))\n",
    "INPUT_DIR = config['INPUT_DIR']\n",
    "OUTPUT_DIR = config['OUTPUT_DIR']\n",
    "TWEET_DIR = config['TWEET_DIR']\n",
    "NUM_CLUSTERS = config['NUM_CLUSTERS']\n",
    "events = open(INPUT_DIR + 'event_names.txt', 'r').read().splitlines()\n",
    "time_dict = json.load(open(INPUT_DIR + \"event_year.json\",\"r\"))\n",
    "shooter_race = json.load(open(INPUT_DIR + \"shooters_race.json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering = ['noRT', 'clustered']\n",
    "cluster_method = [None, 'relative']\n",
    "leaveout = [True, False]\n",
    "method = ['posterior', 'mutual_information', 'chi_square']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(f, c, l, m, b):\n",
    "    cluster_method = method_name(c, c)\n",
    "    leaveout = method_name(l, 'leaveout')\n",
    "    filename = 'polarization_' + m + '_' + f + cluster_method + leaveout + '.json'\n",
    "    if b:\n",
    "        filename = 'between_topic_' + filename\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(e):\n",
    "    label = e.split('_')\n",
    "    new_label = []\n",
    "    for l in label:\n",
    "        new_label.append(l[0].upper() + l[1:])\n",
    "    new_label = ' '.join(new_label)\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for plotting overall polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(polarization_dict, filename):\n",
    "    x = []\n",
    "    y = []\n",
    "    y_random = []\n",
    "    labels=[]\n",
    "    ex = ['fort_lauderdale']  # we exclude Fort Lauderdale because we only have data for the first day after the shooting\n",
    "    for e, t in time_dict.items():\n",
    "        if e in ex:\n",
    "            continue\n",
    "        new_label = get_label(e)\n",
    "\n",
    "        x_val = float(2000+t)\n",
    "        y_val = float(polarization_dict[e][0])\n",
    "        y_random_val = float(float(polarization_dict[e][1]))\n",
    "        x.append(x_val)\n",
    "        y.append(y_val)\n",
    "        y_random.append(y_random_val)\n",
    "        labels.append(new_label)\n",
    "        #labels.append(plt.text(x_val, y_val, new_label, fontsize=8))\n",
    "    df = pd.DataFrame.from_dict({'year':np.array(x * 2), 'polarization':np.array(y + y_random), 'label':labels * 2, 'is_actual':['actual value']* len(y) + ['value resulting from random party assignment']* len(y)})\n",
    "    df.to_csv(OUTPUT_DIR + filename.replace('.json', '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarization_posterior_noRT_leaveout.json found\n",
      "polarization_posterior_noRT.json found\n",
      "between_topic_polarization_posterior_clustered_relative_leaveout.json found\n",
      "between_topic_polarization_posterior_clustered_relative.json found\n",
      "polarization_mutual_information_noRT_leaveout.json found\n",
      "polarization_mutual_information_noRT.json found\n",
      "between_topic_polarization_mutual_information_clustered_relative_leaveout.json found\n",
      "between_topic_polarization_mutual_information_clustered_relative.json found\n",
      "polarization_chi_square_noRT_leaveout.json found\n",
      "polarization_chi_square_noRT.json found\n",
      "between_topic_polarization_chi_square_clustered_relative_leaveout.json found\n",
      "between_topic_polarization_chi_square_clustered_relative.json found\n"
     ]
    }
   ],
   "source": [
    "for m in method:\n",
    "    for f in filtering:\n",
    "        for c in cluster_method:\n",
    "            for l in leaveout:\n",
    "                for b in [True, False]:\n",
    "                    filename = get_filename(f, c, l, m, b)\n",
    "                    try:\n",
    "                        file = json.load(open(OUTPUT_DIR + filename,\"r\"))\n",
    "                    except:\n",
    "                        continue\n",
    "                    print(filename, 'found')\n",
    "                    save_csv(file, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for plotting within topic polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_within_topic_values(e, method, leaveout, cluster_method):\n",
    "    within_topic_pol = json.load(open(TWEET_DIR +e+\"/\"+e+\"_topic_polarization_\"+method + cluster_method+leaveout+\".json\",\"r\"))\n",
    "    # get the topic proportions\n",
    "    topics = pd.read_csv(TWEET_DIR + e + '/' + e + '_kmeans_topics_' + str(NUM_CLUSTERS) + '.csv')\n",
    "    if cluster_method != '':\n",
    "        _, topics = get_assigned_indices_relative(topics) if cluster_method == '_relative' else get_assigned_indices_absolute(topics)\n",
    "\n",
    "    within_topic_pol_actual= (np.array([float(within_topic_pol[str(i)][0]) for i in range(NUM_CLUSTERS)]) * np.bincount(topics['topic_0'])).sum() / len(topics)\n",
    "    within_topic_pol_random = (np.array([float(within_topic_pol[str(i)][1]) for i in range(NUM_CLUSTERS)]) * np.bincount(topics['topic_0'])).sum() / len(topics)\n",
    "    \n",
    "    return within_topic_pol_actual, within_topic_pol_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_within_topic_csv(method, leaveout, cluster_method='_relative'):\n",
    "    print(method, leaveout)\n",
    "    leaveout = method_name(leaveout, 'leaveout')\n",
    "    x = []\n",
    "    y = []\n",
    "    y_random = []\n",
    "    labels=[]\n",
    "    ex = ['fort_lauderdale']  # we exclude Fort Lauderdale because we only have data for the first day after the shooting\n",
    "    for e, t in time_dict.items():\n",
    "        if e in ex:\n",
    "            continue\n",
    "        new_label = get_label(e)\n",
    "        \n",
    "        x_val = float(2000+t)\n",
    "        y_val, y_random_val = get_within_topic_values(e, method, leaveout, cluster_method)\n",
    "        x.append(x_val)\n",
    "        y.append(y_val)\n",
    "        y_random.append(y_random_val)\n",
    "        labels.append(new_label)\n",
    "        #labels.append(plt.text(x_val, y_val, new_label, fontsize=8))\n",
    "    df = pd.DataFrame.from_dict({'year':np.array(x * 2), 'polarization':np.array(y + y_random), 'label':labels * 2, 'is_actual':['actual value']* len(y) + ['value resulting from random party assignment']* len(y)})\n",
    "    df.to_csv(OUTPUT_DIR + \"within_topic_polarization_\"+method+cluster_method+leaveout+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior True\n",
      "posterior False\n",
      "mutual_information True\n",
      "mutual_information False\n",
      "chi_square True\n",
      "chi_square False\n"
     ]
    }
   ],
   "source": [
    "for m in method:\n",
    "    for l in leaveout:\n",
    "        save_within_topic_csv(m, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for plotting within vs between topic polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_csv(method, leaveout, cluster_method='_relative'):\n",
    "    leaveout = method_name(leaveout, 'leaveout')\n",
    "    try:\n",
    "        between_topic_filename = 'between_topic_polarization_' + method + '_clustered' + cluster_method + leaveout + '.json'\n",
    "        between_topic_pol = json.load(open(OUTPUT_DIR + between_topic_filename,\"r\"))\n",
    "        print(between_topic_filename)\n",
    "    except:\n",
    "        return\n",
    "    x = []\n",
    "    y_between = []\n",
    "    y_within = []\n",
    "    labels=[]\n",
    "    race = []\n",
    "    ex = ['fort_lauderdale']\n",
    "    for e, t in time_dict.items():\n",
    "        if e in ex:\n",
    "            continue\n",
    "        new_label = get_label(e)\n",
    "        x_val = float(2000+t)\n",
    "        y_between_val = float(between_topic_pol[e][0])\n",
    "        y_within_val, _ = get_within_topic_values(e, method, leaveout, cluster_method)\n",
    "        x.append(x_val)\n",
    "        y_between.append(y_between_val)\n",
    "        y_within.append(y_within_val)\n",
    "        labels.append(new_label)\n",
    "        race.append(shooter_race[e])\n",
    "        #labels.append(plt.text(x_val, y_val, new_label, fontsize=8))\n",
    "    df = pd.DataFrame.from_dict({'year':np.array(x * 2), 'polarization':np.array(y_between + y_within), 'label':labels * 2, 'kind':['between-topic']* len(y_between) + ['within-topic']* len(y_within), 'race':race * 2})\n",
    "    df.to_csv(OUTPUT_DIR + \"topic_polarization_\"+method+cluster_method+leaveout+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between_topic_polarization_posterior_clustered_relative_leaveout.json\n",
      "between_topic_polarization_posterior_clustered_relative.json\n",
      "between_topic_polarization_mutual_information_clustered_relative_leaveout.json\n",
      "between_topic_polarization_mutual_information_clustered_relative.json\n",
      "between_topic_polarization_chi_square_clustered_relative_leaveout.json\n",
      "between_topic_polarization_chi_square_clustered_relative.json\n"
     ]
    }
   ],
   "source": [
    "for m in method:\n",
    "    for l in leaveout:\n",
    "        save_topic_csv(m, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine polarization over time values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_temporal_csv(method, leaveout):\n",
    "    dicts = []\n",
    "    for e in events:\n",
    "        vals = np.load(TWEET_DIR + e + '/' + e + '_polarization_over_time_noRT.npy')\n",
    "        label = e.split('_')\n",
    "        new_label = []\n",
    "        for l in label:\n",
    "            new_label.append(l[0].upper() + l[1:])\n",
    "        new_label = ' '.join(new_label)\n",
    "        for i in range(vals.shape[0]):\n",
    "            d = {}\n",
    "            d['event'] = new_label\n",
    "            d['leaveout'] = vals[i, 0]\n",
    "            d['time'] = vals[i, 3]\n",
    "            d['size'] = vals[i, 2]\n",
    "            d['squared_diff'] = np.abs(vals[i, 1] - .5)\n",
    "            dicts.append(d)\n",
    "    df = pd.DataFrame(dicts)\n",
    "    df.to_csv(OUTPUT_DIR + 'temporal_polarization_'+method+'_noRT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior\n",
      "mutual_information\n",
      "chi_square\n"
     ]
    }
   ],
   "source": [
    "for m in method:\n",
    "    print(m)\n",
    "    save_temporal_csv(m, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(OUTPUT_DIR + 'temporal_polarization_posterior_noRT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['over_random'] = df['leaveout'] / .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['squared_diff'] < 0.05]\n",
    "#df = df[df['event'].isin(['Vegas', 'Orlando'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>leaveout</th>\n",
       "      <th>size</th>\n",
       "      <th>squared_diff</th>\n",
       "      <th>time</th>\n",
       "      <th>over_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.532192</td>\n",
       "      <td>326987.0</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.064384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>116050.0</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.086092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.543513</td>\n",
       "      <td>69787.0</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.087025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.542220</td>\n",
       "      <td>47815.0</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.084439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.548898</td>\n",
       "      <td>29459.0</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.097796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.559574</td>\n",
       "      <td>18544.0</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.119148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.557199</td>\n",
       "      <td>17056.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.114399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.548795</td>\n",
       "      <td>16231.0</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.097590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.559147</td>\n",
       "      <td>13370.0</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.118294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Vegas</td>\n",
       "      <td>0.564666</td>\n",
       "      <td>11443.0</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.129332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     event  leaveout      size  squared_diff  time  over_random\n",
       "120  Vegas  0.532192  326987.0      0.000068   1.0     1.064384\n",
       "121  Vegas  0.543046  116050.0      0.000221   2.0     1.086092\n",
       "122  Vegas  0.543513   69787.0      0.000504   3.0     1.087025\n",
       "123  Vegas  0.542220   47815.0      0.000700   4.0     1.084439\n",
       "124  Vegas  0.548898   29459.0      0.000698   5.0     1.097796\n",
       "125  Vegas  0.559574   18544.0      0.000144   6.0     1.119148\n",
       "126  Vegas  0.557199   17056.0      0.000011   7.0     1.114399\n",
       "127  Vegas  0.548795   16231.0      0.001126   8.0     1.097590\n",
       "128  Vegas  0.559147   13370.0      0.001163   9.0     1.118294\n",
       "129  Vegas  0.564666   11443.0      0.000788  10.0     1.129332"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['event'] == 'Vegas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leaveout</th>\n",
       "      <th>size</th>\n",
       "      <th>squared_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.527534</td>\n",
       "      <td>46933.523810</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.533188</td>\n",
       "      <td>20351.428571</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.541436</td>\n",
       "      <td>11659.238095</td>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.533888</td>\n",
       "      <td>7094.190476</td>\n",
       "      <td>0.007060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.530235</td>\n",
       "      <td>4993.809524</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.538207</td>\n",
       "      <td>3732.523810</td>\n",
       "      <td>0.003954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.523617</td>\n",
       "      <td>2764.666667</td>\n",
       "      <td>0.006683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.523772</td>\n",
       "      <td>2820.190476</td>\n",
       "      <td>0.003956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.530502</td>\n",
       "      <td>2907.380952</td>\n",
       "      <td>0.004546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.531563</td>\n",
       "      <td>1981.666667</td>\n",
       "      <td>0.008035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      leaveout          size  squared_diff\n",
       "time                                      \n",
       "1.0   0.527534  46933.523810      0.000526\n",
       "2.0   0.533188  20351.428571      0.001061\n",
       "3.0   0.541436  11659.238095      0.004103\n",
       "4.0   0.533888   7094.190476      0.007060\n",
       "5.0   0.530235   4993.809524      0.001950\n",
       "6.0   0.538207   3732.523810      0.003954\n",
       "7.0   0.523617   2764.666667      0.006683\n",
       "8.0   0.523772   2820.190476      0.003956\n",
       "9.0   0.530502   2907.380952      0.004546\n",
       "10.0  0.531563   1981.666667      0.008035"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('time').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leaveout         1.074689\n",
       "size             0.046482\n",
       "squared_diff     7.468382\n",
       "time            10.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['time']==10].mean() / df[df['time']==1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine user leaveout scores (this is not used in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for e in events:\n",
    "    df = pd.read_csv(TWEET_DIR + e + '/' + e + '_user_leaveout.csv')\n",
    "    df['event'] = e\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new.to_csv(TWEET_DIR + 'user_leaveouts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
